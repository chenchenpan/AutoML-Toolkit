{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from modeling import get_model_cls\n",
    "from analysis_util import load_encoder, read_file, load_all, get_best_trial, load_model\n",
    "\n",
    "# def shuffle_col(df, col, seed=None):\n",
    "#     new_df = df.copy()\n",
    "#     if seed is None:\n",
    "#         new_df[col] = np.random.permutation(new_df[col])\n",
    "#     else:\n",
    "#         np.random.seed(seed)\n",
    "#         new_df[col] = np.random.permutation(new_df[col])\n",
    "#     return new_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--metadata_file METADATA_FILE]\n",
      "                             [--train_file TRAIN_FILE] [--dev_file DEV_FILE]\n",
      "                             [--test_file TEST_FILE]\n",
      "                             [--use_text_features [USE_TEXT_FEATURES]]\n",
      "                             [--encode_text_with ENCODE_TEXT_WITH]\n",
      "                             [--glove_file GLOVE_FILE] [--max_words MAX_WORDS]\n",
      "                             [--max_sequence_length MAX_SEQUENCE_LENGTH]\n",
      "                             [--output_dir OUTPUT_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\chenchenpan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\Roaming\\jupyter\\runtime\\kernel-3d173a3b-40c5-4a7d-b00a-9f7fcb61a83f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chenchenpan\\onedrive - microsoft\\desktop\\projects\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import collections\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "## check the package version\n",
    "# print(pd.__version__)\n",
    "\n",
    "# # Preprocess data steps:\n",
    "\n",
    "# 1. split dataset\n",
    "# 2. transfer datetime data\n",
    "# 3. encode categorical data\n",
    "# 4. encode boolean type data\n",
    "# 5. normalize data\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # # parameters for select input data and metedata configure files\n",
    "    # parser.add_argument('--data_dir', type=str,\n",
    "    #     # default='/data/home/t-chepan/projects/MS-intern-project/raw_data',\n",
    "    #     help=('directory to load the raw data.'))\n",
    "\n",
    "    # parser.add_argument('--data_name', type=str,\n",
    "    #     # default='kickstarter',\n",
    "    #     help=('which data will be used? (kickstarter Or indiegogo?)'))\n",
    "\n",
    "    parser.add_argument('--metadata_file', type=str,\n",
    "                        # default='metadata.json',\n",
    "                        help=('which tabular metadata file will be used?'))\n",
    "\n",
    "    parser.add_argument('--train_file', type=str,\n",
    "                        help=('which train file will be used?'))\n",
    "\n",
    "    parser.add_argument('--dev_file', type=str,\n",
    "                        help=('which dev file will be used?'))\n",
    "\n",
    "    parser.add_argument('--test_file', type=str,\n",
    "                        # must passing test file when using BERT model,\n",
    "                        help=('which test file will be used?'))\n",
    "\n",
    "    # parameter for using text features\n",
    "    parser.add_argument('--use_text_features', type=str2bool, nargs='?',\n",
    "                        const=True, default=False,\n",
    "                        help=('whether encode the text features or not?'))\n",
    "\n",
    "    parser.add_argument('--encode_text_with', type=str,\n",
    "                        # default='tfidf',\n",
    "                        help=('how to encode the text features? (tfidf, glove)'))\n",
    "\n",
    "    parser.add_argument('--glove_file', type=str,\n",
    "                        # default='/data/home/t-chepan/projects/MS-intern-project/raw_data',\n",
    "                        help=('directory to the GloVe file will be used. (e.g. glove.840B.300d.txt)'))\n",
    "\n",
    "    parser.add_argument('--max_words', type=int,\n",
    "                        # default='/data/home/t-chepan/projects/MS-intern-project/raw_data',\n",
    "                        help=('what is the maximum number of words for encoding text?'))\n",
    "\n",
    "    parser.add_argument('--max_sequence_length', type=int,\n",
    "                        # default='/data/home/t-chepan/projects/MS-intern-project/raw_data',\n",
    "                        help=('what is the maximum sequence length for encoding text?'))\n",
    "\n",
    "    parser.add_argument('--output_dir', type=str,\n",
    "                        # default='/data/home/t-chepan/projects/MS-intern-project/raw_data',\n",
    "                        help=('directory to save the encoded data.'))\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    ### load raw data and related metadata configure file\n",
    "    # if args.data_name is not None and args.data_dir is not None:\n",
    "    #     path_to_data = os.path.join(args.data_dir, args.data_name)\n",
    "    #     path_to_save = os.path.join(args.output_dir, args.data_name)\n",
    "    #     if not os.path.exists(path_to_save):\n",
    "    #         os.makedirs(path_to_save)\n",
    "\n",
    "    # elif args.data_name is None and args.data_dir is not None:\n",
    "    #     path_to_data = args.data_dir\n",
    "    #     path_to_save = args.output_dir\n",
    "\n",
    "    # else:\n",
    "    #     raise argparse.ArgumentTypeError(args.data_name + ' or ' + args.data_dir + \" can't be recognized.\")\n",
    "\n",
    "    # if not os.path.exists(path_to_data):\n",
    "    #     os.makedirs(path_to_data)\n",
    "\n",
    "    # if not os.path.exists(path_to_save):\n",
    "    #     os.makedirs(path_to_save)\n",
    "\n",
    "    # train_path = os.path.join(path_to_data, args.train_file)\n",
    "    # dev_path = os.path.join(path_to_data, args.dev_file)\n",
    "    # test_path = os.path.join(path_to_data, args.test_file)\n",
    "\n",
    "    print(\"Start to load data...\")\n",
    "\n",
    "    path_to_save = args.output_dir\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.makedirs(path_to_save)\n",
    "\n",
    "    df_train = read_file(args.train_file)\n",
    "    df_dev = read_file(args.dev_file)\n",
    "    df_test = read_file(args.test_file)\n",
    "\n",
    "    print('*' * 50)\n",
    "    print('training set size is {}'.format(df_train.shape[0]))\n",
    "    print('dev set size is {}'.format(df_dev.shape[0]))\n",
    "    print('test set size is {}'.format(df_test.shape[0]))\n",
    "\n",
    "    with open(args.metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    print(\"Processing data...\")\n",
    "\n",
    "    if args.use_text_features:\n",
    "        mode = args.encode_text_with\n",
    "        text_config = Mapping()\n",
    "        text_config.mode = mode\n",
    "        text_config.max_words = args.max_words\n",
    "\n",
    "        if mode == 'glove':\n",
    "            # glove_file_path = os.path.join(args.glove_dir, args.glove_file)\n",
    "            text_config.maxlen = args.max_sequence_length\n",
    "            text_config.embeddings_index = open_glove(args.glove_file)\n",
    "            text_config.embedding_dim = list(text_config.embeddings_index.values())[0].shape[-1]\n",
    "\n",
    "        if mode != 'glove' and mode != 'tfidf':\n",
    "            raise argparse.ArgumentTypeError(mode, \"can't be recognized.\")\n",
    "\n",
    "    else:\n",
    "        text_config = None\n",
    "\n",
    "    encoder = Encoder(metadata, text_config)\n",
    "\n",
    "    y_train, X_train_struc, X_train_text = encoder.fit_transform(df_train)\n",
    "    y_dev, X_dev_struc, X_dev_text = encoder.transform(df_dev)\n",
    "    y_test, X_test_struc, X_test_text = encoder.transform(df_test)\n",
    "\n",
    "    if encoder.text_config is not None and encoder.text_config.mode == 'glove':\n",
    "        f_path = os.path.join(path_to_save, 'embedding_matrix.npy')\n",
    "        text_config.embedding_matrix_path = f_path\n",
    "        with open(f_path, 'wb') as f:\n",
    "            np.save(f, encoder.text_config.embedding_matrix)\n",
    "        del encoder.text_config.embedding_matrix\n",
    "\n",
    "    path = os.path.join(path_to_save, 'encoder.pkl')\n",
    "    dump(encoder, open(path, 'wb'))\n",
    "\n",
    "    metadata_path = os.path.join(path_to_save, 'metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    if text_config is not None:\n",
    "        text_config_path = os.path.join(path_to_save, 'text_config.json')\n",
    "        with open(text_config_path, 'w') as f:\n",
    "            json.dump(encoder.text_config, f, indent=4)\n",
    "\n",
    "    ### save the encoded data ###\n",
    "    output_list = [y_train, X_train_struc, X_train_text, y_dev, X_dev_struc,\n",
    "                   X_dev_text, y_test, X_test_struc, X_test_text]\n",
    "    path_name_list = ['y_train', 'X_train_struc', 'X_train_text', 'y_dev', 'X_dev_struc',\n",
    "                      'X_dev_text', 'y_test', 'X_test_struc', 'X_test_text']\n",
    "\n",
    "    for i, e in enumerate(output_list):\n",
    "        if e is not None:\n",
    "            e_path = os.path.join(path_to_save, '{}.npy'.format(path_name_list[i]))\n",
    "            np.save(e_path, e)\n",
    "\n",
    "    print('Saved the encoded text inputs!')\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    filename, file_extension = os.path.splitext(path)\n",
    "    if file_extension == '.csv':\n",
    "        sep = ','\n",
    "    elif file_extension == '.tsv':\n",
    "        sep = '\\t'\n",
    "    else:\n",
    "        raise ValueError('Unknown type of file: {}. Please add .csv or .tsv.'.format(path))\n",
    "    df = pd.read_csv(path, sep=sep)\n",
    "    return df\n",
    "\n",
    "\n",
    "## use dict like object\n",
    "class Mapping(dict):\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name in self:\n",
    "            del self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def contain_nontext_features(metadata):\n",
    "    n_dtype = len(metadata.keys())\n",
    "\n",
    "    if n_dtype == 1 and 'input_text' in metadata.keys():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def separate_input_output_cols(df, metadata):\n",
    "    \"\"\"According to the metadata, separate the input features, output features and\n",
    "        different types of input features.\n",
    "\n",
    "    Args:\n",
    "      df: a DataFrame that stores the raw data.\n",
    "      metadata: a dictionary that stores the detail description for features.\n",
    "        metadata = {\n",
    "        'output_type': 'classes' for classification task (or it can be 'numbers' for regression task)\n",
    "        'input_features': ['TenantId','CreatedDate', ...],\n",
    "        'output_label': ['AR_exchange_06','AR_sharepoint_06', ...],\n",
    "        'input_bool': ['HasEXO','HasSPO', ...],\n",
    "        'input_categorical': ['CountryCode', 'Languange', ...],\n",
    "        'input_datetime': ['CreatedDate', ...],\n",
    "        'input_int': [...] ,\n",
    "        'input_float': [...]\n",
    "        }\n",
    "    Returns:\n",
    "      df_y: a DataFrame that stores the output labels\n",
    "      df_X_text: a DataFrame that stores the textual input\n",
    "      df_X_float: a DataFrame that stores the float inputs\n",
    "      df_X_int: a DataFrame that stores the integer inputs\n",
    "      df_X_cat: a DataFrame that stores the categorical inputs\n",
    "      df_X_datetime: a DataFrame that stores the datetime inputs\n",
    "      df_X_bool: a DataFrame that stores the boolean inputs\n",
    "\n",
    "    \"\"\"\n",
    "    # input_cols = metadata['input_features']\n",
    "    output_cols = metadata['output_label']\n",
    "    input_text_cols = metadata['input_text']\n",
    "    input_float_cols = metadata['input_float']\n",
    "    input_int_cols = metadata['input_int']\n",
    "    input_cat_cols = metadata['input_categorical']\n",
    "    input_datetime_cols = metadata['input_datetime']\n",
    "    input_bool_cols = metadata['input_bool']\n",
    "\n",
    "    df_y = df.loc[:, output_cols]\n",
    "    df_X_text = df.loc[:, input_text_cols]\n",
    "    df_X_float = df.loc[:, input_float_cols]\n",
    "    df_X_int = df.loc[:, input_int_cols]\n",
    "    df_X_cat = df.loc[:, input_cat_cols]\n",
    "    df_X_datetime = df.loc[:, input_datetime_cols]\n",
    "    df_X_bool = df.loc[:, input_bool_cols]\n",
    "\n",
    "    return df_y, df_X_text, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool\n",
    "\n",
    "\n",
    "def encode_datetime(df_X_datetime):\n",
    "    \"\"\"Encode the datetime inputs from '2/5/2014 5:31:19 AM' format\n",
    "        to a numerical number of UTC format.\n",
    "\n",
    "    Args:\n",
    "      df_: a DataFrame that only stores the datetime inputs.\n",
    "\n",
    "    Returns:\n",
    "      X_datetime: a numpy array that contains the encoded datetime inputs.\n",
    "      datetime_cols: a list that contains the datetime colunms name.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cols = df_X_datetime.columns\n",
    "    for i in cols:\n",
    "        df_X_datetime[i] = pd.to_datetime(df_X_datetime[i], utc=True,\n",
    "                                          errors='coerce').astype(int, errors='ignore')\n",
    "\n",
    "    X_datetime = df_X_datetime.to_numpy()\n",
    "\n",
    "    return X_datetime\n",
    "\n",
    "\n",
    "def encode_bool(df_X_bool):\n",
    "    \"\"\"Encode the numerical and boolean inputs.\n",
    "\n",
    "    Args:\n",
    "      df_X_bool: a DataFrame that stores the boolean inputs\n",
    "\n",
    "    Returns:\n",
    "      X_bool: a numpy array that contains the encoded boolean inputs.\n",
    "\n",
    "    \"\"\"\n",
    "    X_bool = df_X_bool.astype(int).to_numpy()\n",
    "    return X_bool\n",
    "\n",
    "\n",
    "def encode_num(df_X_num):\n",
    "    \"\"\"Encode the numerical and boolean inputs.\n",
    "\n",
    "    Args:\n",
    "      df_X_num: a DataFrame that stores the numerical inputs\n",
    "\n",
    "    Returns:\n",
    "      X_num: a numpy array that contains the float inputs.\n",
    "\n",
    "    \"\"\"\n",
    "    X_num = df_X_num.to_numpy()\n",
    "    return X_num\n",
    "\n",
    "\n",
    "def encode_y(metadata, df_y, y_encoder):\n",
    "    if metadata['output_type'] == 'classes':\n",
    "        # encode class values as integers\n",
    "        y_arr = df_y.values\n",
    "        if y_encoder is None:\n",
    "            y_encoder = LabelEncoder()\n",
    "            y = y_encoder.fit_transform(y_arr)\n",
    "        else:\n",
    "            y = y_encoder.transform(y_arr)\n",
    "\n",
    "        if len(y_encoder.classes_) > 2:\n",
    "            # convert integers to dummy variables (i.e. one hot encoded)\n",
    "            y = np_utils.to_categorical(y)\n",
    "\n",
    "    elif metadata['output_type'] == 'numbers':\n",
    "        y = df_y.to_numpy()\n",
    "        y_encoder = None\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Unknown type of output: {}'.format(metadata['output_type']))\n",
    "\n",
    "    return y, y_encoder\n",
    "\n",
    "\n",
    "def encode_strucdata(metadata, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool, vectorizer, scaler):\n",
    "    \"\"\"Encode the meta data part in dataset, such as numerical and categorical data.\n",
    "\n",
    "    \"\"\"\n",
    "    print('Starting to encode structural data...')\n",
    "\n",
    "    # df_y, _, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool = separate_input_output_cols(df, metadata)\n",
    "\n",
    "    X_list = []\n",
    "    cols_name = []\n",
    "\n",
    "    if df_X_float.shape[1] > 0:\n",
    "        X_float = encode_num(df_X_float)\n",
    "        X_list.append(X_float)\n",
    "        cols_name += metadata['input_float']\n",
    "\n",
    "    if df_X_int.shape[1] > 0:\n",
    "        X_int = encode_num(df_X_int)\n",
    "        X_list.append(X_int)\n",
    "        cols_name += metadata['input_int']\n",
    "\n",
    "    if df_X_datetime.shape[1] > 0:\n",
    "        X_datetime = encode_datetime(df_X_datetime)\n",
    "        X_list.append(X_datetime)\n",
    "        cols_name += metadata['input_datetime']\n",
    "\n",
    "    if X_list:\n",
    "        ### normalize all the inputs except boolean, categorical, and text features\n",
    "        X_arr = np.concatenate(X_list, axis=1)\n",
    "\n",
    "        if scaler == None:\n",
    "            scaler = StandardScaler()\n",
    "            X_struc = scaler.fit_transform(X_arr)\n",
    "        else:\n",
    "            X_struc = scaler.transform(X_arr)\n",
    "        assert len(cols_name) == X_struc.shape[1]\n",
    "        print('Except boolean, categorical and text input data after encoding, the shape is {}'.format(X_struc.shape))\n",
    "        print('we have {} columns.'.format(len(cols_name)))\n",
    "    else:\n",
    "        X_struc = None\n",
    "\n",
    "    ### encode boolean columns\n",
    "    if df_X_bool.shape[1] > 0:\n",
    "        X_bool = encode_bool(df_X_bool)\n",
    "        cols_name += metadata['input_bool']\n",
    "        if X_struc is None:\n",
    "            X_struc = X_bool\n",
    "        else:\n",
    "            X_struc = np.concatenate([X_struc, X_bool], axis=1)\n",
    "\n",
    "    ### encode the categorical columns\n",
    "    if df_X_cat.shape[1] > 0:\n",
    "        X_cat_dict = df_X_cat.to_dict(orient='records')\n",
    "\n",
    "        if vectorizer == None:\n",
    "            vectorizer = DictVectorizer(sparse=False)\n",
    "            X_cat = vectorizer.fit_transform(X_cat_dict)\n",
    "\n",
    "        else:\n",
    "            X_cat = vectorizer.transform(X_cat_dict)\n",
    "\n",
    "        vocab = vectorizer.vocabulary_\n",
    "        vocab_od = collections.OrderedDict(sorted(vocab.items(), key=lambda x: x[1]))\n",
    "        cat_encoded_cols = list(vocab_od.keys())\n",
    "        cols_name += cat_encoded_cols\n",
    "        if X_struc is None:\n",
    "            X_struc = X_cat\n",
    "        else:\n",
    "            X_struc = np.concatenate([X_struc, X_cat], axis=1)\n",
    "\n",
    "    assert len(cols_name) == X_struc.shape[1]\n",
    "    print('Non-text input data after encoding, the shape is {}'.format(X_struc.shape))\n",
    "    print('We have {} columns.'.format(len(cols_name)))\n",
    "\n",
    "    return X_struc, vectorizer, scaler\n",
    "\n",
    "\n",
    "def open_glove(glove_file_path):\n",
    "    print('Indexing word vectors.')\n",
    "\n",
    "    embeddings_index = {}\n",
    "    f = open(glove_file_path, encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def encode_textdata(df_X_text, tokenizer, mode, max_words, maxlen):\n",
    "    ## encode text columns, encoded text features should not be normalized.\n",
    "\n",
    "    print('Starting to encode text inputs...')\n",
    "\n",
    "    texts = df_X_text.iloc[:, 0].values.astype('U')\n",
    "    print('Found %s texts.' % len(texts))\n",
    "\n",
    "    if mode == 'tfidf':\n",
    "        if tokenizer is None:\n",
    "            tokenizer = Tokenizer(num_words=max_words)\n",
    "            tokenizer.fit_on_texts(texts)\n",
    "        X_text = tokenizer.texts_to_matrix(texts, mode='tfidf')\n",
    "        print('tfidf X_text shape: {}'.format(X_text.shape))\n",
    "\n",
    "    elif mode == 'glove':\n",
    "        # vectorize the text samples into a 2D integer tensor\n",
    "        if tokenizer is None:\n",
    "            tokenizer = Tokenizer(num_words=max_words, oov_token='<UNK>')\n",
    "            tokenizer.fit_on_texts(texts)\n",
    "            tokenizer.word_index = {e: i for e, i in tokenizer.word_index.items() if i <= max_words}\n",
    "            # tokenizer.word_index[tokenizer.oov_token] = max_words + 1\n",
    "\n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "        X_text = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "    else:\n",
    "        raise ValueError('Unknown text processing mode: {}'.format(mode))\n",
    "\n",
    "    return X_text, tokenizer  ### need to save embedding_matrix as well\n",
    "\n",
    "\n",
    "def encode_dataset(df, metadata, y_encoder=None, vectorizer=None, scaler=None, tokenizer=None, mode=None,\n",
    "                   max_words=None, maxlen=None):\n",
    "    print('Starting to encode dataset...')\n",
    "\n",
    "    df_y, df_X_text, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool = separate_input_output_cols(df, metadata)\n",
    "\n",
    "    y, y_encoder = encode_y(metadata, df_y, y_encoder)\n",
    "\n",
    "    # check if exist non-text data\n",
    "    if df_X_float.shape[1] + df_X_int.shape[1] + df_X_cat.shape[1] + df_X_datetime.shape[1] + df_X_bool.shape[1] > 0:\n",
    "        X_struc, vectorizer, scaler = encode_strucdata(metadata, df_X_float, df_X_int, df_X_cat, df_X_datetime,\n",
    "                                                       df_X_bool, vectorizer, scaler)\n",
    "    else:\n",
    "        X_struc, vectorizer, scaler = None, None, None\n",
    "\n",
    "    print(\"complete encoding part of structural data!\")\n",
    "\n",
    "    if not metadata['input_text'] or mode == None:\n",
    "        X_text, tokenizer = None, None\n",
    "    else:\n",
    "        X_text, tokenizer = encode_textdata(df_X_text, tokenizer, mode, max_words, maxlen)\n",
    "\n",
    "    print(\"complete encoding part of textual data!\")\n",
    "    return y, y_encoder, X_struc, X_text, vectorizer, scaler, tokenizer\n",
    "\n",
    "\n",
    "class Encoder(object):\n",
    "\n",
    "    def __init__(self, metadata, text_config):\n",
    "        self.text_config = text_config\n",
    "        self.metadata = metadata\n",
    "        self.has_nontext = contain_nontext_features(metadata)\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        if self.has_nontext and self.text_config is None:\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, _ = encode_dataset(df, self.metadata,\n",
    "                                                                                                 mode=None)\n",
    "\n",
    "        elif self.text_config.mode == 'tfidf':\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, self.tokenizer = encode_dataset(\n",
    "                df, self.metadata, mode='tfidf', max_words=self.text_config.max_words)\n",
    "\n",
    "        elif self.text_config.mode == 'glove':\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, self.tokenizer = encode_dataset(\n",
    "                df, self.metadata, mode='glove', max_words=self.text_config.max_words, maxlen=self.text_config.maxlen)\n",
    "\n",
    "            word_index = self.tokenizer.word_index\n",
    "            # prepare embedding matrix\n",
    "            embedding_matrix = np.zeros((len(word_index) + 1, self.text_config.embedding_dim))\n",
    "            for word, i in word_index.items():\n",
    "                embedding_vector = self.text_config.embeddings_index.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    # words not found in embedding index will be all-zeros.\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "            self.text_config.embedding_matrix = embedding_matrix\n",
    "            del self.text_config.embeddings_index\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unknown type of text_config: {}'.format(self.text_config.mode))\n",
    "\n",
    "        return y, X_struc, X_text\n",
    "\n",
    "    def transform(self, df):\n",
    "        if self.text_config is None:\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(df, self.metadata, y_encoder=self.y_encoder,\n",
    "                                                            vectorizer=self.vectorizer, scaler=self.scaler)\n",
    "\n",
    "        elif self.text_config.mode == 'tfidf':\n",
    "\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(\n",
    "                df, self.metadata, y_encoder=self.y_encoder,\n",
    "                vectorizer=self.vectorizer, scaler=self.scaler, tokenizer=self.tokenizer, mode='tfidf',\n",
    "                max_words=self.text_config.max_words)\n",
    "        elif self.text_config.mode == 'glove':\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(\n",
    "                df, self.metadata, y_encoder=self.y_encoder,\n",
    "                vectorizer=self.vectorizer, scaler=self.scaler, tokenizer=self.tokenizer,\n",
    "                mode='glove', max_words=self.text_config.max_words, maxlen=self.text_config.maxlen)\n",
    "        else:\n",
    "            raise ValueError('Unknown type of text_config: {}'.format(self.text_config.mode))\n",
    "\n",
    "        return y, X_struc, X_text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "output_dir = 'recommend_V2_NN/outputs/nn_outputs/'\n",
    "data_file = 'recommend_V2_NN/data/raw_data/tenant_data_featurized.csv'\n",
    "\n",
    "# output_dir = 'recommend_V3/outputs_1031/nn_outputs/'\n",
    "# data_file = 'recommend_V3/data/raw_data/tenant_data_featurized_joint.csv'\n",
    "df = read_file(data_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                               TenantId   Age Age Group        AreaName  \\\n0  f431229b-d3d4-482f-99de-949a81db0616  1456     <10yr            APAC   \n1  0005e37c-da1d-49a3-9411-87f64edb84e1  1475     <10yr   United States   \n2  f43134df-b1e9-4162-a41a-b6253acdad2f  1406     <10yr  Western Europe   \n3  000609e0-8e9c-40f8-83d3-5de84bac7aff   675      <3yr              UK   \n4  f4314553-921a-447d-be35-8cdf761dd6c4  1650     <10yr   United States   \n\n  CountryCode                 IndustryName  TotalUsers  \\\n0         KOR                       Mining           7   \n1         USA                       Others           7   \n2         BEL  Other Partner Prof Services           3   \n3         GBR                       Others           3   \n4         USA                       Others           5   \n\n   TotalUsersWithSkuAssigned  SubscriptionsCount  EXOEnabledUsers  ...  \\\n0                          6                   2                0  ...   \n1                          2                   2                2  ...   \n2                          1                   2                0  ...   \n3                          2                   1                2  ...   \n4                          2                   2                2  ...   \n\n   PowerPoint_AllUp  OneNote_AllUp  Outlook_AllUp  EXO_AllUp  SPO_AllUp  \\\n0               3.0            0.0            0.0        0.0        0.0   \n1               0.0            0.0            0.0        2.0        0.0   \n2               1.0            0.0            1.0        0.0        0.0   \n3               0.0            0.0            0.0        2.0        0.0   \n4               0.0            0.0            1.0        2.0        0.0   \n\n   OD4B_AllUp  Teams_AllUp  SfB_AllUp  SkypeTeams_AllUp  WordExcel_AllUp  \n0         1.0          0.0        0.0               0.0              5.0  \n1         0.0          0.0        0.0               0.0              2.0  \n2         1.0          0.0        0.0               0.0              1.0  \n3         0.0          0.0        0.0               0.0              2.0  \n4         1.0          0.0        0.0               0.0              1.0  \n\n[5 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TenantId</th>\n      <th>Age</th>\n      <th>Age Group</th>\n      <th>AreaName</th>\n      <th>CountryCode</th>\n      <th>IndustryName</th>\n      <th>TotalUsers</th>\n      <th>TotalUsersWithSkuAssigned</th>\n      <th>SubscriptionsCount</th>\n      <th>EXOEnabledUsers</th>\n      <th>...</th>\n      <th>PowerPoint_AllUp</th>\n      <th>OneNote_AllUp</th>\n      <th>Outlook_AllUp</th>\n      <th>EXO_AllUp</th>\n      <th>SPO_AllUp</th>\n      <th>OD4B_AllUp</th>\n      <th>Teams_AllUp</th>\n      <th>SfB_AllUp</th>\n      <th>SkypeTeams_AllUp</th>\n      <th>WordExcel_AllUp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f431229b-d3d4-482f-99de-949a81db0616</td>\n      <td>1456</td>\n      <td>&lt;10yr</td>\n      <td>APAC</td>\n      <td>KOR</td>\n      <td>Mining</td>\n      <td>7</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0005e37c-da1d-49a3-9411-87f64edb84e1</td>\n      <td>1475</td>\n      <td>&lt;10yr</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>Others</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f43134df-b1e9-4162-a41a-b6253acdad2f</td>\n      <td>1406</td>\n      <td>&lt;10yr</td>\n      <td>Western Europe</td>\n      <td>BEL</td>\n      <td>Other Partner Prof Services</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000609e0-8e9c-40f8-83d3-5de84bac7aff</td>\n      <td>675</td>\n      <td>&lt;3yr</td>\n      <td>UK</td>\n      <td>GBR</td>\n      <td>Others</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f4314553-921a-447d-be35-8cdf761dd6c4</td>\n      <td>1650</td>\n      <td>&lt;10yr</td>\n      <td>United States</td>\n      <td>USA</td>\n      <td>Others</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "(1539331, 49)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best metric: 0.009605477564036846, best_trial: recommend_V2_NN/outputs/nn_outputs/model_3\n"
     ]
    }
   ],
   "source": [
    "best_trial = get_best_trial(output_dir)\n",
    "# model, encoder = load_all(best_trial)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend_V2_NN/outputs/nn_outputs/model_3\n"
     ]
    }
   ],
   "source": [
    "print(best_trial)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "model_config_file = os.path.join(best_trial, 'model_config.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_config_file, 'r') as f:\n",
    "    model_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder_path = 'recommend_V2_NN/data/encoded_data/encoder.pkl'\n",
    "file = open(encoder_path, 'rb')\n",
    "\n",
    "# with open(encoder_path, 'rb') as f:\n",
    "#     encoder = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model_cls(model_config['model_type'])(encoder.text_config, model_config)\n",
    "model.load(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_type': 'mlp',\n 'output_dir': '/home/chenchenpan/Projects/AutoML-Toolkit/recommend_NewTenant/outputs/nn_outputs/model_3',\n 'task_type': 'regression',\n 'num_classes': 8,\n 'combine': 'concate',\n 'n_layers_dense': 2,\n 'hidden_size_dense': 48,\n 'n_layers_lstm': 2,\n 'hidden_size_lstm': 32,\n 'dropout_rate_lstm': 0.0,\n 'n_layers_output': 2,\n 'hidden_size_output': 30,\n 'optimizer': 'adam',\n 'learning_rate': 0.0017137964331140918,\n 'clipnorm': 5.0,\n 'patience': 5,\n 'n_epochs': 93,\n 'batch_size': 128,\n 'verbose': 0,\n 'encoded_data_dir': '/home/chenchenpan/Projects/AutoML-Toolkit/recommend_NewTenant/data/encoded_data'}"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to encode dataset...\n",
      "Starting to encode structural data...\n",
      "Except boolean, categorical and text input data after encoding, the shape is (1539331, 16)\n",
      "we have 16 columns.\n",
      "Non-text input data after encoding, the shape is (1539331, 269)\n",
      "We have 269 columns.\n",
      "complete encoding part of structural data!\n",
      "complete encoding part of textual data!\n"
     ]
    }
   ],
   "source": [
    "y, X, _ = encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%time pred = model.predict(X, output_dir=best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1539331, 8)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sklearn.metrics.mean_squared_error(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0776622018421674"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the rough Coverage rate (workload based)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delta = pred - y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sum(delta > 0.1) / (delta.shape[0] * delta.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1539331, 8)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_path = os.path.join(best_trial, 'predictions.npy')\n",
    "with open(prediction_path, 'rb') as f:\n",
    "    predictions = np.load(f)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 5.6258410e-01,  4.8001297e-02,  1.2509432e-01,  2.4061067e-01,\n         2.8289899e-01,  3.8563248e-02,  8.3149374e-02,  8.6173630e-01],\n       [ 3.6770325e-02, -9.9395588e-04, -9.5082819e-03,  1.0196586e+00,\n         6.2753841e-02,  5.7511833e-02, -8.3401799e-03,  9.2455888e-01],\n       [ 8.5995263e-01,  2.2960518e-02,  8.9035857e-01,  3.9760172e-01,\n         7.9427135e-01, -1.0074703e-03,  5.5240393e-02,  8.3288765e-01],\n       [ 3.2278907e-02, -5.8760606e-03, -9.9389777e-03,  1.0331113e+00,\n         7.2634585e-02, -8.1720082e-03,  4.7505319e-02,  9.3563837e-01],\n       [ 2.1419208e-02,  4.7179945e-03,  9.2222083e-01,  9.8093635e-01,\n         8.5940027e-01, -4.4819890e-03, -2.3044020e-02,  9.3730634e-01],\n       [ 1.4560264e-02, -1.8729735e-02,  6.0159671e-01,  9.1402030e-01,\n         7.6716095e-02, -8.2609830e-03,  1.4683819e-01, -6.5230384e-02],\n       [ 4.4051688e-02, -5.1864646e-03,  4.5810994e-03,  8.0772245e-01,\n         8.5491222e-01, -2.5453595e-03,  9.7830987e-01,  8.1992388e-01],\n       [ 8.1291310e-03,  2.0086300e-02, -9.4024278e-03,  9.1454011e-01,\n         3.1320849e-01, -6.4877449e-03, -2.8675258e-02,  8.4959251e-01],\n       [ 5.3051524e-03, -1.2731656e-02, -9.6290931e-03,  1.0953765e+00,\n         6.1294325e-02, -1.3075429e-02, -3.3705831e-03, -4.4896379e-02],\n       [ 5.2125167e-02,  4.1973535e-03, -1.9641183e-02,  1.0897501e+00,\n         6.1019078e-02, -1.6527269e-02, -7.5565904e-02, -2.8256759e-02]],\n      dtype=float32)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 5.6258410e-01,  4.8001297e-02,  1.2509432e-01,  2.4061067e-01,\n         2.8289899e-01,  3.8563248e-02,  8.3149374e-02,  8.6173630e-01],\n       [ 3.6770325e-02, -9.9395588e-04, -9.5082819e-03,  1.0196586e+00,\n         6.2753841e-02,  5.7511833e-02, -8.3401799e-03,  9.2455888e-01],\n       [ 8.5995263e-01,  2.2960518e-02,  8.9035857e-01,  3.9760172e-01,\n         7.9427135e-01, -1.0074703e-03,  5.5240393e-02,  8.3288765e-01],\n       [ 3.2278907e-02, -5.8760606e-03, -9.9389777e-03,  1.0331113e+00,\n         7.2634585e-02, -8.1720082e-03,  4.7505319e-02,  9.3563837e-01],\n       [ 2.1419208e-02,  4.7179945e-03,  9.2222083e-01,  9.8093635e-01,\n         8.5940027e-01, -4.4819890e-03, -2.3044020e-02,  9.3730634e-01],\n       [ 1.4560264e-02, -1.8729735e-02,  6.0159671e-01,  9.1402030e-01,\n         7.6716095e-02, -8.2609830e-03,  1.4683819e-01, -6.5230384e-02],\n       [ 4.4051688e-02, -5.1864646e-03,  4.5810994e-03,  8.0772245e-01,\n         8.5491222e-01, -2.5453595e-03,  9.7830987e-01,  8.1992388e-01],\n       [ 8.1291310e-03,  2.0086300e-02, -9.4024278e-03,  9.1454011e-01,\n         3.1320849e-01, -6.4877449e-03, -2.8675258e-02,  8.4959251e-01],\n       [ 5.3051524e-03, -1.2731656e-02, -9.6290931e-03,  1.0953765e+00,\n         6.1294325e-02, -1.3075429e-02, -3.3705831e-03, -4.4896379e-02],\n       [ 5.2125167e-02,  4.1973535e-03, -1.9641183e-02,  1.0897501e+00,\n         6.1019078e-02, -1.6527269e-02, -7.5565904e-02, -2.8256759e-02]],\n      dtype=float32)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred - predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "coverage_file_path = os.path.join('recommend_V2_NN/outputs', 'coverage_calculate_1231.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "y_column_name = [\n",
    "    \"TenantId\",\n",
    "    \"PowerPoint_MAR\",\n",
    "    \"OneNote_MAR\",\n",
    "    \"Outlook_MAR\",\n",
    "    \"EXO_MAR\",\n",
    "    \"OD4B_MAR\",\n",
    "    \"SPO_MAR\",\n",
    "    \"SkypeTeams_MAR\",\n",
    "    \"WordExcel_MAR\"]\n",
    "pred_column_name = [\n",
    "    \"PowerPoint_MAR_pred\",\n",
    "    \"OneNote_MAR_pred\",\n",
    "    \"Outlook_MAR_pred\",\n",
    "    \"EXO_MAR_pred\",\n",
    "    \"OD4B_MAR_pred\",\n",
    "    \"SPO_MAR_pred\",\n",
    "    \"SkypeTeams_MAR_pred\",\n",
    "    \"WordExcel_MAR_pred\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "   PowerPoint_MAR_pred  OneNote_MAR_pred  Outlook_MAR_pred  EXO_MAR_pred  \\\n0             0.562584          0.048001          0.125094      0.240611   \n1             0.036770         -0.000994         -0.009508      1.019659   \n2             0.859953          0.022961          0.890359      0.397602   \n3             0.032279         -0.005876         -0.009939      1.033111   \n4             0.021419          0.004718          0.922221      0.980936   \n\n   OD4B_MAR_pred  SPO_MAR_pred  SkypeTeams_MAR_pred  WordExcel_MAR_pred  \\\n0       0.282899      0.038563             0.083149            0.861736   \n1       0.062754      0.057512            -0.008340            0.924559   \n2       0.794271     -0.001007             0.055240            0.832888   \n3       0.072635     -0.008172             0.047505            0.935638   \n4       0.859400     -0.004482            -0.023044            0.937306   \n\n                               TenantId  \n0  f431229b-d3d4-482f-99de-949a81db0616  \n1  0005e37c-da1d-49a3-9411-87f64edb84e1  \n2  f43134df-b1e9-4162-a41a-b6253acdad2f  \n3  000609e0-8e9c-40f8-83d3-5de84bac7aff  \n4  f4314553-921a-447d-be35-8cdf761dd6c4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PowerPoint_MAR_pred</th>\n      <th>OneNote_MAR_pred</th>\n      <th>Outlook_MAR_pred</th>\n      <th>EXO_MAR_pred</th>\n      <th>OD4B_MAR_pred</th>\n      <th>SPO_MAR_pred</th>\n      <th>SkypeTeams_MAR_pred</th>\n      <th>WordExcel_MAR_pred</th>\n      <th>TenantId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.562584</td>\n      <td>0.048001</td>\n      <td>0.125094</td>\n      <td>0.240611</td>\n      <td>0.282899</td>\n      <td>0.038563</td>\n      <td>0.083149</td>\n      <td>0.861736</td>\n      <td>f431229b-d3d4-482f-99de-949a81db0616</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.036770</td>\n      <td>-0.000994</td>\n      <td>-0.009508</td>\n      <td>1.019659</td>\n      <td>0.062754</td>\n      <td>0.057512</td>\n      <td>-0.008340</td>\n      <td>0.924559</td>\n      <td>0005e37c-da1d-49a3-9411-87f64edb84e1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.859953</td>\n      <td>0.022961</td>\n      <td>0.890359</td>\n      <td>0.397602</td>\n      <td>0.794271</td>\n      <td>-0.001007</td>\n      <td>0.055240</td>\n      <td>0.832888</td>\n      <td>f43134df-b1e9-4162-a41a-b6253acdad2f</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.032279</td>\n      <td>-0.005876</td>\n      <td>-0.009939</td>\n      <td>1.033111</td>\n      <td>0.072635</td>\n      <td>-0.008172</td>\n      <td>0.047505</td>\n      <td>0.935638</td>\n      <td>000609e0-8e9c-40f8-83d3-5de84bac7aff</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.021419</td>\n      <td>0.004718</td>\n      <td>0.922221</td>\n      <td>0.980936</td>\n      <td>0.859400</td>\n      <td>-0.004482</td>\n      <td>-0.023044</td>\n      <td>0.937306</td>\n      <td>f4314553-921a-447d-be35-8cdf761dd6c4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(predictions, columns=pred_column_name)\n",
    "pred_df['TenantId'] = df.loc[:,'TenantId'].copy()\n",
    "pred_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "                               TenantId  PowerPoint_MAR  OneNote_MAR  \\\n0  f431229b-d3d4-482f-99de-949a81db0616             0.5          0.0   \n1  0005e37c-da1d-49a3-9411-87f64edb84e1             0.0          0.0   \n2  f43134df-b1e9-4162-a41a-b6253acdad2f             0.5          0.0   \n3  000609e0-8e9c-40f8-83d3-5de84bac7aff             0.0          0.0   \n4  f4314553-921a-447d-be35-8cdf761dd6c4             0.0          0.0   \n\n   Outlook_MAR  EXO_MAR  OD4B_MAR  SPO_MAR  SkypeTeams_MAR  WordExcel_MAR  \n0          0.0      0.0      0.16      0.0             0.0           0.83  \n1          0.0      1.0      0.00      0.0             0.0           1.00  \n2          0.5      0.0      0.50      0.0             0.0           0.50  \n3          0.0      1.0      0.00      0.0             0.0           1.00  \n4          1.0      1.0      1.00      0.0             0.0           1.00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TenantId</th>\n      <th>PowerPoint_MAR</th>\n      <th>OneNote_MAR</th>\n      <th>Outlook_MAR</th>\n      <th>EXO_MAR</th>\n      <th>OD4B_MAR</th>\n      <th>SPO_MAR</th>\n      <th>SkypeTeams_MAR</th>\n      <th>WordExcel_MAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f431229b-d3d4-482f-99de-949a81db0616</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0005e37c-da1d-49a3-9411-87f64edb84e1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f43134df-b1e9-4162-a41a-b6253acdad2f</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000609e0-8e9c-40f8-83d3-5de84bac7aff</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f4314553-921a-447d-be35-8cdf761dd6c4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = df.loc[:, y_column_name].copy()\n",
    "y_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "                               TenantId  PowerPoint_MAR  OneNote_MAR  \\\n0  f431229b-d3d4-482f-99de-949a81db0616             0.5          0.0   \n1  0005e37c-da1d-49a3-9411-87f64edb84e1             0.0          0.0   \n2  f43134df-b1e9-4162-a41a-b6253acdad2f             0.5          0.0   \n3  000609e0-8e9c-40f8-83d3-5de84bac7aff             0.0          0.0   \n4  f4314553-921a-447d-be35-8cdf761dd6c4             0.0          0.0   \n\n   Outlook_MAR  EXO_MAR  OD4B_MAR  SPO_MAR  SkypeTeams_MAR  WordExcel_MAR  \\\n0          0.0      0.0      0.16      0.0             0.0           0.83   \n1          0.0      1.0      0.00      0.0             0.0           1.00   \n2          0.5      0.0      0.50      0.0             0.0           0.50   \n3          0.0      1.0      0.00      0.0             0.0           1.00   \n4          1.0      1.0      1.00      0.0             0.0           1.00   \n\n   PowerPoint_MAR_pred  OneNote_MAR_pred  Outlook_MAR_pred  EXO_MAR_pred  \\\n0             0.562584          0.048001          0.125094      0.240611   \n1             0.036770         -0.000994         -0.009508      1.019659   \n2             0.859953          0.022961          0.890359      0.397602   \n3             0.032279         -0.005876         -0.009939      1.033111   \n4             0.021419          0.004718          0.922221      0.980936   \n\n   OD4B_MAR_pred  SPO_MAR_pred  SkypeTeams_MAR_pred  WordExcel_MAR_pred  \n0       0.282899      0.038563             0.083149            0.861736  \n1       0.062754      0.057512            -0.008340            0.924559  \n2       0.794271     -0.001007             0.055240            0.832888  \n3       0.072635     -0.008172             0.047505            0.935638  \n4       0.859400     -0.004482            -0.023044            0.937306  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TenantId</th>\n      <th>PowerPoint_MAR</th>\n      <th>OneNote_MAR</th>\n      <th>Outlook_MAR</th>\n      <th>EXO_MAR</th>\n      <th>OD4B_MAR</th>\n      <th>SPO_MAR</th>\n      <th>SkypeTeams_MAR</th>\n      <th>WordExcel_MAR</th>\n      <th>PowerPoint_MAR_pred</th>\n      <th>OneNote_MAR_pred</th>\n      <th>Outlook_MAR_pred</th>\n      <th>EXO_MAR_pred</th>\n      <th>OD4B_MAR_pred</th>\n      <th>SPO_MAR_pred</th>\n      <th>SkypeTeams_MAR_pred</th>\n      <th>WordExcel_MAR_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f431229b-d3d4-482f-99de-949a81db0616</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.83</td>\n      <td>0.562584</td>\n      <td>0.048001</td>\n      <td>0.125094</td>\n      <td>0.240611</td>\n      <td>0.282899</td>\n      <td>0.038563</td>\n      <td>0.083149</td>\n      <td>0.861736</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0005e37c-da1d-49a3-9411-87f64edb84e1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.036770</td>\n      <td>-0.000994</td>\n      <td>-0.009508</td>\n      <td>1.019659</td>\n      <td>0.062754</td>\n      <td>0.057512</td>\n      <td>-0.008340</td>\n      <td>0.924559</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f43134df-b1e9-4162-a41a-b6253acdad2f</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.859953</td>\n      <td>0.022961</td>\n      <td>0.890359</td>\n      <td>0.397602</td>\n      <td>0.794271</td>\n      <td>-0.001007</td>\n      <td>0.055240</td>\n      <td>0.832888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000609e0-8e9c-40f8-83d3-5de84bac7aff</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.032279</td>\n      <td>-0.005876</td>\n      <td>-0.009939</td>\n      <td>1.033111</td>\n      <td>0.072635</td>\n      <td>-0.008172</td>\n      <td>0.047505</td>\n      <td>0.935638</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f4314553-921a-447d-be35-8cdf761dd6c4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.021419</td>\n      <td>0.004718</td>\n      <td>0.922221</td>\n      <td>0.980936</td>\n      <td>0.859400</td>\n      <td>-0.004482</td>\n      <td>-0.023044</td>\n      <td>0.937306</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_df = y_df.merge(pred_df, how='inner', on='TenantId')\n",
    "coverage_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "(1539331, 17)"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "coverage_df.to_csv(coverage_file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend_V2_NN/outputs\\coverage_calculate_1231.csv\n"
     ]
    }
   ],
   "source": [
    "print(coverage_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "                               TenantId  PowerPoint_MAR  OneNote_MAR  \\\n0  f431229b-d3d4-482f-99de-949a81db0616             0.5          0.0   \n1  0005e37c-da1d-49a3-9411-87f64edb84e1             0.0          0.0   \n2  f43134df-b1e9-4162-a41a-b6253acdad2f             0.5          0.0   \n3  000609e0-8e9c-40f8-83d3-5de84bac7aff             0.0          0.0   \n4  f4314553-921a-447d-be35-8cdf761dd6c4             0.0          0.0   \n\n   Outlook_MAR  EXO_MAR  OD4B_MAR  SPO_MAR  SkypeTeams_MAR  WordExcel_MAR  \\\n0          0.0      0.0      0.16      0.0             0.0           0.83   \n1          0.0      1.0      0.00      0.0             0.0           1.00   \n2          0.5      0.0      0.50      0.0             0.0           0.50   \n3          0.0      1.0      0.00      0.0             0.0           1.00   \n4          1.0      1.0      1.00      0.0             0.0           1.00   \n\n   PowerPoint_MAR_pred  OneNote_MAR_pred  Outlook_MAR_pred  EXO_MAR_pred  \\\n0             0.562584          0.048001          0.125094      0.240611   \n1             0.036770         -0.000994         -0.009508      1.019659   \n2             0.859953          0.022961          0.890359      0.397602   \n3             0.032279         -0.005876         -0.009939      1.033111   \n4             0.021419          0.004718          0.922221      0.980936   \n\n   OD4B_MAR_pred  SPO_MAR_pred  SkypeTeams_MAR_pred  WordExcel_MAR_pred  \n0       0.282899      0.038563             0.083149            0.861736  \n1       0.062754      0.057512            -0.008340            0.924559  \n2       0.794271     -0.001007             0.055240            0.832888  \n3       0.072635     -0.008172             0.047505            0.935638  \n4       0.859400     -0.004482            -0.023044            0.937306  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TenantId</th>\n      <th>PowerPoint_MAR</th>\n      <th>OneNote_MAR</th>\n      <th>Outlook_MAR</th>\n      <th>EXO_MAR</th>\n      <th>OD4B_MAR</th>\n      <th>SPO_MAR</th>\n      <th>SkypeTeams_MAR</th>\n      <th>WordExcel_MAR</th>\n      <th>PowerPoint_MAR_pred</th>\n      <th>OneNote_MAR_pred</th>\n      <th>Outlook_MAR_pred</th>\n      <th>EXO_MAR_pred</th>\n      <th>OD4B_MAR_pred</th>\n      <th>SPO_MAR_pred</th>\n      <th>SkypeTeams_MAR_pred</th>\n      <th>WordExcel_MAR_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f431229b-d3d4-482f-99de-949a81db0616</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.83</td>\n      <td>0.562584</td>\n      <td>0.048001</td>\n      <td>0.125094</td>\n      <td>0.240611</td>\n      <td>0.282899</td>\n      <td>0.038563</td>\n      <td>0.083149</td>\n      <td>0.861736</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0005e37c-da1d-49a3-9411-87f64edb84e1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.036770</td>\n      <td>-0.000994</td>\n      <td>-0.009508</td>\n      <td>1.019659</td>\n      <td>0.062754</td>\n      <td>0.057512</td>\n      <td>-0.008340</td>\n      <td>0.924559</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f43134df-b1e9-4162-a41a-b6253acdad2f</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.859953</td>\n      <td>0.022961</td>\n      <td>0.890359</td>\n      <td>0.397602</td>\n      <td>0.794271</td>\n      <td>-0.001007</td>\n      <td>0.055240</td>\n      <td>0.832888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000609e0-8e9c-40f8-83d3-5de84bac7aff</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.032279</td>\n      <td>-0.005876</td>\n      <td>-0.009939</td>\n      <td>1.033111</td>\n      <td>0.072635</td>\n      <td>-0.008172</td>\n      <td>0.047505</td>\n      <td>0.935638</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f4314553-921a-447d-be35-8cdf761dd6c4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.021419</td>\n      <td>0.004718</td>\n      <td>0.922221</td>\n      <td>0.980936</td>\n      <td>0.859400</td>\n      <td>-0.004482</td>\n      <td>-0.023044</td>\n      <td>0.937306</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(coverage_file_path)\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}