{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from modeling import get_model_cls\n",
    "from analysis_util import read_file, load_all, get_best_trial\n",
    "from encode_data import Encoder, Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'recommend_V2_NN/outputs/nn_outputs'\n",
    "data_file = 'recommend_V2_NN/data/raw_data/Hackathon_data_JanandFeb.csv'\n",
    "df = read_file(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best metric: 0.009605477564036846, best_trial: recommend_V2_NN/outputs/nn_outputs/model_3\n"
     ]
    }
   ],
   "source": [
    "best_trial = get_best_trial(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_file = os.path.join('recommend_V2_NN/outputs/nn_outputs/model_3',\n",
    "#                                  best_trial,\n",
    "                                 'model_config.json').replace(\"\\\\\",\"/\") #required for windows machine\n",
    "with open(model_config_file, 'r') as f:\n",
    "    model_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = 'recommend_V2_NN/data/encoded_data/encoder.pkl'\n",
    "file = open(encoder_path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 22:48:26.658016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-19 22:48:26.661468: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-19 22:48:26.664760: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-AD7TO7E): /proc/driver/nvidia/version does not exist\n",
      "2022-04-19 22:48:26.682627: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = get_model_cls(model_config['model_type'])(encoder.text_config, model_config)\n",
    "# model.load(best_trial)\n",
    "model.load('recommend_V2_NN/outputs/nn_outputs/model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to encode dataset...\n",
      "Starting to encode structural data...\n",
      "Except boolean, categorical and text input data, the X shape is (1203, 16)\n",
      "we have normalized 16 columns: ['Age', 'TotalUsers', 'TotalUsersWithSkuAssigned', 'SubscriptionsCount', 'EXOEnabledUsers', 'SPOEnabledUsers', 'SFBEnabledUsers', 'OD4BEnabledUsers', 'TeamEnabledUsers', 'PaidSeats', 'PaidEXOSeats', 'PaidOD4BSeats', 'PaidProplusSeats', 'PaidSPOSeats', 'PaidTeamsSeats', 'PaidSFBSeats'].\n",
      "Non-text input data after encoding, the shape is (1203, 269)\n",
      "We have 269 columns.\n",
      "complete encoding part of structural data!\n",
      "complete encoding part of textual data!\n"
     ]
    }
   ],
   "source": [
    "y, X, _ = encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 93.8 ms, total: 203 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "# %time pred = model.predict(X, output_dir=best_trial)\n",
    "%time pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('recommend_V2_NN/outputs/', 'prediction.npy')\n",
    "np.save(path_to_save, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028676112490326793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y, pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " structual_data (InputLayer)  [(None, 269)]            0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 48)                12960     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 30)                1470      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 248       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,960\n",
      "Trainable params: 17,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prediction results table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58349025,  0.00180508, -0.00200222, ...,  0.81120396,\n",
       "         0.35594106,  0.6604699 ],\n",
       "       [ 0.52957183,  0.15545826, -0.00549661, ...,  0.93781674,\n",
       "         0.75286543,  0.76701367],\n",
       "       [ 0.17081356, -0.0142157 , -0.00290386, ...,  0.27520618,\n",
       "         0.75183576,  0.4805825 ],\n",
       "       ...,\n",
       "       [ 0.2802615 ,  0.01078228,  0.93976665, ...,  0.8571981 ,\n",
       "         0.9241239 ,  0.6799935 ],\n",
       "       [ 0.44014445,  0.18876457,  0.609166  , ...,  0.0699264 ,\n",
       "         0.8602202 ,  0.22869389],\n",
       "       [ 1.0378836 ,  0.9306137 ,  0.8792633 , ...,  0.43960828,\n",
       "         0.9003432 ,  0.90925205]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = 'recommend_V2_NN/data/raw_data/metadata.json'\n",
    "with open(metadata_file, 'r') as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regression'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config['task_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_col = metadata['output_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PowerPoint_MAR_pred',\n",
       " 'OneNote_MAR_pred',\n",
       " 'Outlook_MAR_pred',\n",
       " 'EXO_MAR_pred',\n",
       " 'OD4B_MAR_pred',\n",
       " 'SPO_MAR_pred',\n",
       " 'SkypeTeams_MAR_pred',\n",
       " 'WordExcel_MAR_pred']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_col = []\n",
    "for c in output_col:\n",
    "    w = c + '_pred'\n",
    "    pred_col.append(w)\n",
    "pred_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenantId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>AreaName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>IndustryName</th>\n",
       "      <th>TotalUsers</th>\n",
       "      <th>TotalUsersWithSkuAssigned</th>\n",
       "      <th>SubscriptionsCount</th>\n",
       "      <th>EXOEnabledUsers</th>\n",
       "      <th>SPOEnabledUsers</th>\n",
       "      <th>SFBEnabledUsers</th>\n",
       "      <th>OD4BEnabledUsers</th>\n",
       "      <th>TeamEnabledUsers</th>\n",
       "      <th>PaidSeats</th>\n",
       "      <th>PaidEXOSeats</th>\n",
       "      <th>PaidOD4BSeats</th>\n",
       "      <th>PaidProplusSeats</th>\n",
       "      <th>PaidSPOSeats</th>\n",
       "      <th>PaidTeamsSeats</th>\n",
       "      <th>PaidSFBSeats</th>\n",
       "      <th>PowerPoint_MAR_Rank</th>\n",
       "      <th>OneNote_MAR_Rank</th>\n",
       "      <th>Outlook_MAR_Rank</th>\n",
       "      <th>EXO_MAR_Rank</th>\n",
       "      <th>OD4B_MAR_Rank</th>\n",
       "      <th>SPO_MAR_Rank</th>\n",
       "      <th>SkypeTeams_MAR_Rank</th>\n",
       "      <th>WordExcel_MAR_Rank</th>\n",
       "      <th>PowerPoint_MAR</th>\n",
       "      <th>OneNote_MAR</th>\n",
       "      <th>Outlook_MAR</th>\n",
       "      <th>EXO_MAR</th>\n",
       "      <th>OD4B_MAR</th>\n",
       "      <th>SPO_MAR</th>\n",
       "      <th>SkypeTeams_MAR</th>\n",
       "      <th>WordExcel_MAR</th>\n",
       "      <th>Excel_AllUp</th>\n",
       "      <th>Word_AllUp</th>\n",
       "      <th>PowerPoint_AllUp</th>\n",
       "      <th>OneNote_AllUp</th>\n",
       "      <th>Outlook_AllUp</th>\n",
       "      <th>EXO_AllUp</th>\n",
       "      <th>SPO_AllUp</th>\n",
       "      <th>OD4B_AllUp</th>\n",
       "      <th>Teams_AllUp</th>\n",
       "      <th>SfB_AllUp</th>\n",
       "      <th>SkypeTeams_AllUp</th>\n",
       "      <th>WordExcel_AllUp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1f51839-24c4-428b-a708-0019dc6842ee</td>\n",
       "      <td>2863</td>\n",
       "      <td>&lt;10yr</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>85</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.63</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e441e2e0-ef38-469a-a0d5-004701ccaf9b</td>\n",
       "      <td>2672</td>\n",
       "      <td>&lt;10yr</td>\n",
       "      <td>MEA</td>\n",
       "      <td>ISR</td>\n",
       "      <td>Other - Unsegmented</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30edaab1-2f20-4e20-b98b-0088595779ca</td>\n",
       "      <td>1363</td>\n",
       "      <td>&lt;10yr</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Others</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7433f7ec-d409-4daa-82cb-00cea0acf72d</td>\n",
       "      <td>315</td>\n",
       "      <td>&lt;1yr</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>NLD</td>\n",
       "      <td>Others</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1aa5a1d5-30d7-4728-ba6f-0121b75e7a68</td>\n",
       "      <td>536</td>\n",
       "      <td>&lt;3yr</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>Others</td>\n",
       "      <td>457</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>101</td>\n",
       "      <td>86</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               TenantId   Age Age Group        AreaName  \\\n",
       "0  a1f51839-24c4-428b-a708-0019dc6842ee  2863     <10yr   United States   \n",
       "1  e441e2e0-ef38-469a-a0d5-004701ccaf9b  2672     <10yr             MEA   \n",
       "2  30edaab1-2f20-4e20-b98b-0088595779ca  1363     <10yr   United States   \n",
       "3  7433f7ec-d409-4daa-82cb-00cea0acf72d   315      <1yr  Western Europe   \n",
       "4  1aa5a1d5-30d7-4728-ba6f-0121b75e7a68   536      <3yr           India   \n",
       "\n",
       "  CountryCode           IndustryName  TotalUsers  TotalUsersWithSkuAssigned  \\\n",
       "0         USA  Media & Entertainment          85                          8   \n",
       "1         ISR    Other - Unsegmented          38                         18   \n",
       "2         USA                 Others          16                         13   \n",
       "3         NLD                 Others          18                         17   \n",
       "4         IND                 Others         457                         99   \n",
       "\n",
       "   SubscriptionsCount  EXOEnabledUsers  SPOEnabledUsers  SFBEnabledUsers  \\\n",
       "0                   5               19               18               18   \n",
       "1                   6               18               19               18   \n",
       "2                   5               12               11               11   \n",
       "3                   5               17               11               10   \n",
       "4                   5               97              101               86   \n",
       "\n",
       "   OD4BEnabledUsers  TeamEnabledUsers  PaidSeats  PaidEXOSeats  PaidOD4BSeats  \\\n",
       "0                18                18       19.0          19.0           19.0   \n",
       "1                19                19       16.0          16.0           16.0   \n",
       "2                12                11       12.0          12.0           12.0   \n",
       "3                11                11       17.0          17.0            9.0   \n",
       "4               101               101       86.0          86.0           86.0   \n",
       "\n",
       "   PaidProplusSeats  PaidSPOSeats  PaidTeamsSeats  PaidSFBSeats  \\\n",
       "0              19.0          19.0            19.0          19.0   \n",
       "1              14.0          16.0            16.0          16.0   \n",
       "2              11.0          11.0            11.0          11.0   \n",
       "3               9.0           9.0             9.0           9.0   \n",
       "4              86.0          86.0            86.0          86.0   \n",
       "\n",
       "   PowerPoint_MAR_Rank  OneNote_MAR_Rank  Outlook_MAR_Rank  EXO_MAR_Rank  \\\n",
       "0                    2                 4                 4             1   \n",
       "1                    4                 6                 7             1   \n",
       "2                    6                 7                 7             1   \n",
       "3                    1                 2                 3             1   \n",
       "4                    2                 4                 5             1   \n",
       "\n",
       "   OD4B_MAR_Rank  SPO_MAR_Rank  SkypeTeams_MAR_Rank  WordExcel_MAR_Rank  \\\n",
       "0              3             1                    3                   2   \n",
       "1              5             1                    3                   2   \n",
       "2              3             5                    2                   4   \n",
       "3              1             1                    1                   1   \n",
       "4              2             1                    1                   3   \n",
       "\n",
       "   PowerPoint_MAR  OneNote_MAR  Outlook_MAR  EXO_MAR  OD4B_MAR  SPO_MAR  \\\n",
       "0            0.63         0.00          0.0     0.84      0.52     0.84   \n",
       "1            0.71         0.07          0.0     1.00      0.56     1.00   \n",
       "2            0.18         0.00          0.0     1.00      0.75     0.27   \n",
       "3            1.00         0.55          0.0     1.00      1.00     1.00   \n",
       "4            0.98         0.55          0.0     1.00      0.98     1.00   \n",
       "\n",
       "   SkypeTeams_MAR  WordExcel_MAR  Excel_AllUp  Word_AllUp  PowerPoint_AllUp  \\\n",
       "0            0.52           0.63         11.0        12.0              12.0   \n",
       "1            0.87           0.92         12.0        13.0              10.0   \n",
       "2            0.81           0.72          8.0         8.0               2.0   \n",
       "3            1.00           1.00         13.0        12.0              10.0   \n",
       "4            1.00           0.94         81.0        79.0              85.0   \n",
       "\n",
       "   OneNote_AllUp  Outlook_AllUp  EXO_AllUp  SPO_AllUp  OD4B_AllUp  \\\n",
       "0            0.0            0.0       16.0       16.0        10.0   \n",
       "1            1.0            0.0       16.0       17.0         9.0   \n",
       "2            0.0            0.0       13.0        3.0         9.0   \n",
       "3            5.0            0.0       17.0       14.0        11.0   \n",
       "4           48.0            0.0       90.0      193.0        85.0   \n",
       "\n",
       "   Teams_AllUp  SfB_AllUp  SkypeTeams_AllUp  WordExcel_AllUp  \n",
       "0         10.0        0.0              10.0             12.0  \n",
       "1         14.0        0.0              14.0             13.0  \n",
       "2          9.0        0.0               9.0              8.0  \n",
       "3         10.0        0.0              10.0             13.0  \n",
       "4        131.0        3.0             131.0             81.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenantId</th>\n",
       "      <th>PowerPoint_MAR_pred</th>\n",
       "      <th>OneNote_MAR_pred</th>\n",
       "      <th>Outlook_MAR_pred</th>\n",
       "      <th>EXO_MAR_pred</th>\n",
       "      <th>OD4B_MAR_pred</th>\n",
       "      <th>SPO_MAR_pred</th>\n",
       "      <th>SkypeTeams_MAR_pred</th>\n",
       "      <th>WordExcel_MAR_pred</th>\n",
       "      <th>PowerPoint_MAR</th>\n",
       "      <th>OneNote_MAR</th>\n",
       "      <th>Outlook_MAR</th>\n",
       "      <th>EXO_MAR</th>\n",
       "      <th>OD4B_MAR</th>\n",
       "      <th>SPO_MAR</th>\n",
       "      <th>SkypeTeams_MAR</th>\n",
       "      <th>WordExcel_MAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1f51839-24c4-428b-a708-0019dc6842ee</td>\n",
       "      <td>0.583490</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>-0.002002</td>\n",
       "      <td>0.911549</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.811204</td>\n",
       "      <td>0.355941</td>\n",
       "      <td>0.660470</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e441e2e0-ef38-469a-a0d5-004701ccaf9b</td>\n",
       "      <td>0.529572</td>\n",
       "      <td>0.155458</td>\n",
       "      <td>-0.005497</td>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.393121</td>\n",
       "      <td>0.937817</td>\n",
       "      <td>0.752865</td>\n",
       "      <td>0.767014</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30edaab1-2f20-4e20-b98b-0088595779ca</td>\n",
       "      <td>0.170814</td>\n",
       "      <td>-0.014216</td>\n",
       "      <td>-0.002904</td>\n",
       "      <td>0.870951</td>\n",
       "      <td>0.621325</td>\n",
       "      <td>0.275206</td>\n",
       "      <td>0.751836</td>\n",
       "      <td>0.480583</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7433f7ec-d409-4daa-82cb-00cea0acf72d</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.262255</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.782171</td>\n",
       "      <td>0.801193</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.904125</td>\n",
       "      <td>0.708147</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1aa5a1d5-30d7-4728-ba6f-0121b75e7a68</td>\n",
       "      <td>0.475080</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.932760</td>\n",
       "      <td>0.567667</td>\n",
       "      <td>0.844569</td>\n",
       "      <td>0.936444</td>\n",
       "      <td>0.663068</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               TenantId  PowerPoint_MAR_pred  \\\n",
       "0  a1f51839-24c4-428b-a708-0019dc6842ee             0.583490   \n",
       "1  e441e2e0-ef38-469a-a0d5-004701ccaf9b             0.529572   \n",
       "2  30edaab1-2f20-4e20-b98b-0088595779ca             0.170814   \n",
       "3  7433f7ec-d409-4daa-82cb-00cea0acf72d             0.698970   \n",
       "4  1aa5a1d5-30d7-4728-ba6f-0121b75e7a68             0.475080   \n",
       "\n",
       "   OneNote_MAR_pred  Outlook_MAR_pred  EXO_MAR_pred  OD4B_MAR_pred  \\\n",
       "0          0.001805         -0.002002      0.911549       0.255900   \n",
       "1          0.155458         -0.005497      0.991763       0.393121   \n",
       "2         -0.014216         -0.002904      0.870951       0.621325   \n",
       "3          0.262255          0.003674      0.782171       0.801193   \n",
       "4          0.089159          0.000148      0.932760       0.567667   \n",
       "\n",
       "   SPO_MAR_pred  SkypeTeams_MAR_pred  WordExcel_MAR_pred  PowerPoint_MAR  \\\n",
       "0      0.811204             0.355941            0.660470            0.63   \n",
       "1      0.937817             0.752865            0.767014            0.71   \n",
       "2      0.275206             0.751836            0.480583            0.18   \n",
       "3      0.790579             0.904125            0.708147            1.00   \n",
       "4      0.844569             0.936444            0.663068            0.98   \n",
       "\n",
       "   OneNote_MAR  Outlook_MAR  EXO_MAR  OD4B_MAR  SPO_MAR  SkypeTeams_MAR  \\\n",
       "0         0.00          0.0     0.84      0.52     0.84            0.52   \n",
       "1         0.07          0.0     1.00      0.56     1.00            0.87   \n",
       "2         0.00          0.0     1.00      0.75     0.27            0.81   \n",
       "3         0.55          0.0     1.00      1.00     1.00            1.00   \n",
       "4         0.55          0.0     1.00      0.98     1.00            1.00   \n",
       "\n",
       "   WordExcel_MAR  \n",
       "0           0.63  \n",
       "1           0.92  \n",
       "2           0.72  \n",
       "3           1.00  \n",
       "4           0.94  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(data=pred, index=df.TenantId, columns=pred_col)\n",
    "results_df = results_df.reset_index()\n",
    "for c in output_col:\n",
    "    results_df[c] = df[c]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv('results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extract Features from the n layers of a MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "inp = model.model.input\n",
    "out = model.model.layers[4].output\n",
    "functors = K.function([inp], [out]) \n",
    "\n",
    "layer_outs = functors([X])\n",
    "   \n",
    "print(layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = layer_outs[0]\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    filename, file_extension = os.path.splitext(path)\n",
    "    if file_extension == '.csv':\n",
    "        sep = ','\n",
    "    elif file_extension == '.tsv':\n",
    "        sep = '\\t'\n",
    "    else:\n",
    "        raise ValueError('Unknown type of file: {}. Please add .csv or .tsv.'.format(path))\n",
    "    df = pd.read_csv(path, sep=sep)\n",
    "    return df\n",
    "\n",
    "\n",
    "## use dict like object\n",
    "class Mapping(dict):\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in self:\n",
    "            return self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        self[name] = value\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        if name in self:\n",
    "            del self[name]\n",
    "        else:\n",
    "            raise AttributeError(\"No such attribute: \" + name)\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def contain_nontext_features(metadata):\n",
    "    n_dtype = len(metadata.keys())\n",
    "\n",
    "    if n_dtype == 1 and 'input_text' in metadata.keys():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def separate_input_output_cols(df, metadata):\n",
    "    \"\"\"According to the metadata, separate the input features, output features and\n",
    "        different types of input features.\n",
    "\n",
    "    Args:\n",
    "      df: a DataFrame that stores the raw data.\n",
    "      metadata: a dictionary that stores the detail description for features.\n",
    "        metadata = {\n",
    "        'output_type': 'classes' for classification task (or it can be 'numbers' for regression task)\n",
    "        'input_features': ['TenantId','CreatedDate', ...],\n",
    "        'output_label': ['AR_exchange_06','AR_sharepoint_06', ...],\n",
    "        'input_bool': ['HasEXO','HasSPO', ...],\n",
    "        'input_categorical': ['CountryCode', 'Languange', ...],\n",
    "        'input_datetime': ['CreatedDate', ...],\n",
    "        'input_int': [...] ,\n",
    "        'input_float': [...]\n",
    "        }\n",
    "    Returns:\n",
    "      df_y: a DataFrame that stores the output labels\n",
    "      df_X_text: a DataFrame that stores the textual input\n",
    "      df_X_float: a DataFrame that stores the float inputs\n",
    "      df_X_int: a DataFrame that stores the integer inputs\n",
    "      df_X_cat: a DataFrame that stores the categorical inputs\n",
    "      df_X_datetime: a DataFrame that stores the datetime inputs\n",
    "      df_X_bool: a DataFrame that stores the boolean inputs\n",
    "\n",
    "    \"\"\"\n",
    "    # input_cols = metadata['input_features']\n",
    "    output_cols = metadata['output_label']\n",
    "    input_text_cols = metadata['input_text']\n",
    "    input_float_cols = metadata['input_float']\n",
    "    input_int_cols = metadata['input_int']\n",
    "    input_cat_cols = metadata['input_categorical']\n",
    "    input_datetime_cols = metadata['input_datetime']\n",
    "    input_bool_cols = metadata['input_bool']\n",
    "\n",
    "    df_y = df.loc[:, output_cols]\n",
    "    df_X_text = df.loc[:, input_text_cols]\n",
    "    df_X_float = df.loc[:, input_float_cols]\n",
    "    df_X_int = df.loc[:, input_int_cols]\n",
    "    df_X_cat = df.loc[:, input_cat_cols]\n",
    "    df_X_datetime = df.loc[:, input_datetime_cols]\n",
    "    df_X_bool = df.loc[:, input_bool_cols]\n",
    "\n",
    "    return df_y, df_X_text, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool\n",
    "\n",
    "\n",
    "def encode_datetime(df_X_datetime):\n",
    "    \"\"\"Encode the datetime inputs from '2/5/2014 5:31:19 AM' format\n",
    "        to a numerical number of UTC format.\n",
    "\n",
    "    Args:\n",
    "      df_: a DataFrame that only stores the datetime inputs.\n",
    "\n",
    "    Returns:\n",
    "      X_datetime: a numpy array that contains the encoded datetime inputs.\n",
    "      datetime_cols: a list that contains the datetime colunms name.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cols = df_X_datetime.columns\n",
    "    for i in cols:\n",
    "        df_X_datetime[i] = pd.to_datetime(df_X_datetime[i], utc=True,\n",
    "                                          errors='coerce').astype(int, errors='ignore')\n",
    "\n",
    "    X_datetime = df_X_datetime.to_numpy()\n",
    "\n",
    "    return X_datetime\n",
    "\n",
    "\n",
    "def encode_bool(df_X_bool):\n",
    "    \"\"\"Encode the numerical and boolean inputs.\n",
    "\n",
    "    Args:\n",
    "      df_X_bool: a DataFrame that stores the boolean inputs\n",
    "\n",
    "    Returns:\n",
    "      X_bool: a numpy array that contains the encoded boolean inputs.\n",
    "\n",
    "    \"\"\"\n",
    "    X_bool = df_X_bool.astype(int).to_numpy()\n",
    "    return X_bool\n",
    "\n",
    "\n",
    "def encode_num(df_X_num):\n",
    "    \"\"\"Encode the numerical and boolean inputs.\n",
    "\n",
    "    Args:\n",
    "      df_X_num: a DataFrame that stores the numerical inputs\n",
    "\n",
    "    Returns:\n",
    "      X_num: a numpy array that contains the float inputs.\n",
    "\n",
    "    \"\"\"\n",
    "    X_num = df_X_num.to_numpy()\n",
    "    return X_num\n",
    "\n",
    "\n",
    "def encode_y(metadata, df_y, y_encoder):\n",
    "    if metadata['output_type'] == 'classes':\n",
    "        # encode class values as integers\n",
    "        y_arr = df_y.values\n",
    "        if y_encoder is None:\n",
    "            y_encoder = LabelEncoder()\n",
    "            y = y_encoder.fit_transform(y_arr)\n",
    "        else:\n",
    "            y = y_encoder.transform(y_arr)\n",
    "\n",
    "        if len(y_encoder.classes_) > 2:\n",
    "            # convert integers to dummy variables (i.e. one hot encoded)\n",
    "            y = np_utils.to_categorical(y)\n",
    "\n",
    "    elif metadata['output_type'] == 'numbers':\n",
    "        y = df_y.to_numpy()\n",
    "        y_encoder = None\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Unknown type of output: {}'.format(metadata['output_type']))\n",
    "\n",
    "    return y, y_encoder\n",
    "\n",
    "\n",
    "def encode_strucdata(metadata, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool, vectorizer, scaler):\n",
    "    \"\"\"Encode the meta data part in dataset, such as numerical and categorical data.\n",
    "\n",
    "    \"\"\"\n",
    "    print('Starting to encode structural data...')\n",
    "\n",
    "    # df_y, _, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool = separate_input_output_cols(df, metadata)\n",
    "\n",
    "    X_list = []\n",
    "    cols_name = []\n",
    "\n",
    "    if df_X_float.shape[1] > 0:\n",
    "        X_float = encode_num(df_X_float)\n",
    "        X_list.append(X_float)\n",
    "        cols_name += metadata['input_float']\n",
    "\n",
    "    if df_X_int.shape[1] > 0:\n",
    "        X_int = encode_num(df_X_int)\n",
    "        X_list.append(X_int)\n",
    "        cols_name += metadata['input_int']\n",
    "\n",
    "    if df_X_datetime.shape[1] > 0:\n",
    "        X_datetime = encode_datetime(df_X_datetime)\n",
    "        X_list.append(X_datetime)\n",
    "        cols_name += metadata['input_datetime']\n",
    "\n",
    "    if X_list:\n",
    "        ### normalize all the inputs except boolean, categorical, and text features\n",
    "        X_arr = np.concatenate(X_list, axis=1)\n",
    "\n",
    "        if scaler == None:\n",
    "            scaler = StandardScaler()\n",
    "            X_struc = scaler.fit_transform(X_arr)\n",
    "        else:\n",
    "            X_struc = scaler.transform(X_arr)\n",
    "        assert len(cols_name) == X_struc.shape[1]\n",
    "        print('Except boolean, categorical and text input data after encoding, the shape is {}'.format(X_struc.shape))\n",
    "        print('we have {} columns.'.format(len(cols_name)))\n",
    "    else:\n",
    "        X_struc = None\n",
    "\n",
    "    ### encode boolean columns\n",
    "    if df_X_bool.shape[1] > 0:\n",
    "        X_bool = encode_bool(df_X_bool)\n",
    "        cols_name += metadata['input_bool']\n",
    "        if X_struc is None:\n",
    "            X_struc = X_bool\n",
    "        else:\n",
    "            X_struc = np.concatenate([X_struc, X_bool], axis=1)\n",
    "\n",
    "    ### encode the categorical columns\n",
    "    if df_X_cat.shape[1] > 0:\n",
    "        X_cat_dict = df_X_cat.to_dict(orient='records')\n",
    "\n",
    "        if vectorizer == None:\n",
    "            vectorizer = DictVectorizer(sparse=False)\n",
    "            X_cat = vectorizer.fit_transform(X_cat_dict)\n",
    "\n",
    "        else:\n",
    "            X_cat = vectorizer.transform(X_cat_dict)\n",
    "\n",
    "        vocab = vectorizer.vocabulary_\n",
    "        vocab_od = collections.OrderedDict(sorted(vocab.items(), key=lambda x: x[1]))\n",
    "        cat_encoded_cols = list(vocab_od.keys())\n",
    "        cols_name += cat_encoded_cols\n",
    "        if X_struc is None:\n",
    "            X_struc = X_cat\n",
    "        else:\n",
    "            X_struc = np.concatenate([X_struc, X_cat], axis=1)\n",
    "\n",
    "    assert len(cols_name) == X_struc.shape[1]\n",
    "    print('Non-text input data after encoding, the shape is {}'.format(X_struc.shape))\n",
    "    print('We have {} columns.'.format(len(cols_name)))\n",
    "\n",
    "    return X_struc, vectorizer, scaler\n",
    "\n",
    "\n",
    "def open_glove(glove_file_path):\n",
    "    print('Indexing word vectors.')\n",
    "\n",
    "    embeddings_index = {}\n",
    "    f = open(glove_file_path, encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "def encode_textdata(df_X_text, tokenizer, mode, max_words, maxlen):\n",
    "    ## encode text columns, encoded text features should not be normalized.\n",
    "\n",
    "    print('Starting to encode text inputs...')\n",
    "\n",
    "    texts = df_X_text.iloc[:, 0].values.astype('U')\n",
    "    print('Found %s texts.' % len(texts))\n",
    "\n",
    "    if mode == 'tfidf':\n",
    "        if tokenizer is None:\n",
    "            tokenizer = Tokenizer(num_words=max_words)\n",
    "            tokenizer.fit_on_texts(texts)\n",
    "        X_text = tokenizer.texts_to_matrix(texts, mode='tfidf')\n",
    "        print('tfidf X_text shape: {}'.format(X_text.shape))\n",
    "\n",
    "    elif mode == 'glove':\n",
    "        # vectorize the text samples into a 2D integer tensor\n",
    "        if tokenizer is None:\n",
    "            tokenizer = Tokenizer(num_words=max_words, oov_token='<UNK>')\n",
    "            tokenizer.fit_on_texts(texts)\n",
    "            tokenizer.word_index = {e: i for e, i in tokenizer.word_index.items() if i <= max_words}\n",
    "            # tokenizer.word_index[tokenizer.oov_token] = max_words + 1\n",
    "\n",
    "        sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "        X_text = pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "    else:\n",
    "        raise ValueError('Unknown text processing mode: {}'.format(mode))\n",
    "\n",
    "    return X_text, tokenizer  ### need to save embedding_matrix as well\n",
    "\n",
    "\n",
    "def encode_dataset(df, metadata, y_encoder=None, vectorizer=None, scaler=None, tokenizer=None, mode=None,\n",
    "                   max_words=None, maxlen=None):\n",
    "    print('Starting to encode dataset...')\n",
    "\n",
    "    df_y, df_X_text, df_X_float, df_X_int, df_X_cat, df_X_datetime, df_X_bool = separate_input_output_cols(df, metadata)\n",
    "\n",
    "    y, y_encoder = encode_y(metadata, df_y, y_encoder)\n",
    "\n",
    "    # check if exist non-text data\n",
    "    if df_X_float.shape[1] + df_X_int.shape[1] + df_X_cat.shape[1] + df_X_datetime.shape[1] + df_X_bool.shape[1] > 0:\n",
    "        X_struc, vectorizer, scaler = encode_strucdata(metadata, df_X_float, df_X_int, df_X_cat, df_X_datetime,\n",
    "                                                       df_X_bool, vectorizer, scaler)\n",
    "    else:\n",
    "        X_struc, vectorizer, scaler = None, None, None\n",
    "\n",
    "    print(\"complete encoding part of structural data!\")\n",
    "\n",
    "    if not metadata['input_text'] or mode == None:\n",
    "        X_text, tokenizer = None, None\n",
    "    else:\n",
    "        X_text, tokenizer = encode_textdata(df_X_text, tokenizer, mode, max_words, maxlen)\n",
    "\n",
    "    print(\"complete encoding part of textual data!\")\n",
    "    return y, y_encoder, X_struc, X_text, vectorizer, scaler, tokenizer\n",
    "\n",
    "\n",
    "class Encoder(object):\n",
    "\n",
    "    def __init__(self, metadata, text_config):\n",
    "        self.text_config = text_config\n",
    "        self.metadata = metadata\n",
    "        self.has_nontext = contain_nontext_features(metadata)\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        if self.has_nontext and self.text_config is None:\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, _ = encode_dataset(df, self.metadata,\n",
    "                                                                                                 mode=None)\n",
    "\n",
    "        elif self.text_config.mode == 'tfidf':\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, self.tokenizer = encode_dataset(\n",
    "                df, self.metadata, mode='tfidf', max_words=self.text_config.max_words)\n",
    "\n",
    "        elif self.text_config.mode == 'glove':\n",
    "            y, self.y_encoder, X_struc, X_text, self.vectorizer, self.scaler, self.tokenizer = encode_dataset(\n",
    "                df, self.metadata, mode='glove', max_words=self.text_config.max_words, maxlen=self.text_config.maxlen)\n",
    "\n",
    "            word_index = self.tokenizer.word_index\n",
    "            # prepare embedding matrix\n",
    "            embedding_matrix = np.zeros((len(word_index) + 1, self.text_config.embedding_dim))\n",
    "            for word, i in word_index.items():\n",
    "                embedding_vector = self.text_config.embeddings_index.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    # words not found in embedding index will be all-zeros.\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "            self.text_config.embedding_matrix = embedding_matrix\n",
    "            del self.text_config.embeddings_index\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unknown type of text_config: {}'.format(self.text_config.mode))\n",
    "\n",
    "        return y, X_struc, X_text\n",
    "\n",
    "    def transform(self, df):\n",
    "        if self.text_config is None:\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(df, self.metadata, y_encoder=self.y_encoder,\n",
    "                                                            vectorizer=self.vectorizer, scaler=self.scaler)\n",
    "\n",
    "        elif self.text_config.mode == 'tfidf':\n",
    "\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(\n",
    "                df, self.metadata, y_encoder=self.y_encoder,\n",
    "                vectorizer=self.vectorizer, scaler=self.scaler, tokenizer=self.tokenizer, mode='tfidf',\n",
    "                max_words=self.text_config.max_words)\n",
    "        elif self.text_config.mode == 'glove':\n",
    "            y, _, X_struc, X_text, _, _, _ = encode_dataset(\n",
    "                df, self.metadata, y_encoder=self.y_encoder,\n",
    "                vectorizer=self.vectorizer, scaler=self.scaler, tokenizer=self.tokenizer,\n",
    "                mode='glove', max_words=self.text_config.max_words, maxlen=self.text_config.maxlen)\n",
    "        else:\n",
    "            raise ValueError('Unknown type of text_config: {}'.format(self.text_config.mode))\n",
    "\n",
    "        return y, X_struc, X_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('recommend_V2_NN/data/raw_data/Embedding.npy', arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df['TenantId']\n",
    "df_id.to_csv('recommend_V2_NN/data/raw_data/Embedding_id.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[ 5.032131  , -0.3668098 , -0.649486  , ...,  4.        ,\n",
      "         4.        ,  1.        ],\n",
      "       [ 0.41434795,  3.4243884 ,  3.9882743 , ...,  1.        ,\n",
      "         1.        ,  1.        ],\n",
      "       [-1.8065605 , -0.39763254, -0.75488967, ...,  4.        ,\n",
      "         3.        ,  1.        ],\n",
      "       ...,\n",
      "       [ 0.05708297, 11.592417  , 18.270468  , ...,  1.        ,\n",
      "         1.        ,  1.        ],\n",
      "       [ 0.4303449 ,  4.256603  ,  8.994947  , ...,  5.        ,\n",
      "         2.        ,  3.        ],\n",
      "       [ 2.3686407 ,  4.179546  ,  5.7801366 , ...,  4.        ,\n",
      "         5.        ,  3.        ]], dtype=float32)], [array([[0.22717221, 0.        , 1.0796607 , ..., 0.        , 1.6200686 ,\n",
      "        0.773795  ],\n",
      "       [1.7365007 , 0.        , 0.8142006 , ..., 2.155461  , 0.        ,\n",
      "        1.0966704 ],\n",
      "       [1.2287397 , 0.        , 1.2940555 , ..., 0.        , 0.78642535,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [2.6641848 , 0.        , 0.5201439 , ..., 3.0237014 , 0.        ,\n",
      "        4.188305  ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.76684487],\n",
      "       [0.        , 0.        , 0.        , ..., 3.0460236 , 0.75849617,\n",
      "        1.1276941 ]], dtype=float32)], [array([[0.13833332, 0.        , 0.79634523, ..., 0.        , 0.        ,\n",
      "        0.4845667 ],\n",
      "       [2.239542  , 0.        , 0.        , ..., 0.13678333, 0.        ,\n",
      "        2.2456927 ],\n",
      "       [0.        , 0.5347246 , 0.32839257, ..., 0.20757188, 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [3.2288356 , 0.        , 0.        , ..., 3.782079  , 0.        ,\n",
      "        1.5579983 ],\n",
      "       [0.90639395, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.3049544 ],\n",
      "       [0.70037705, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32)], [array([[0.43637273, 0.19248654, 0.        , ..., 0.49346358, 0.        ,\n",
      "        0.        ],\n",
      "       [0.7241524 , 0.        , 1.5053071 , ..., 0.24813223, 1.9847507 ,\n",
      "        0.        ],\n",
      "       [0.717625  , 0.1265817 , 0.3361051 , ..., 0.2632132 , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 2.411275  , ..., 0.        , 3.465631  ,\n",
      "        0.        ],\n",
      "       [0.6263746 , 0.        , 0.51092386, ..., 0.4748239 , 0.        ,\n",
      "        0.        ],\n",
      "       [0.77189493, 0.        , 0.5929653 , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32)], [array([[0.        , 0.        , 0.8008839 , ..., 0.        , 0.        ,\n",
      "        0.72897625],\n",
      "       [1.0228759 , 0.17786534, 0.        , ..., 0.        , 0.        ,\n",
      "        2.002394  ],\n",
      "       [0.        , 0.        , 0.6197164 , ..., 0.        , 0.        ,\n",
      "        1.1903849 ],\n",
      "       ...,\n",
      "       [0.        , 1.5751542 , 0.        , ..., 0.        , 0.        ,\n",
      "        0.4053745 ],\n",
      "       [0.        , 0.        , 0.6374273 , ..., 0.        , 0.        ,\n",
      "        0.6297119 ],\n",
      "       [0.4562768 , 0.02603434, 0.54642045, ..., 0.        , 0.        ,\n",
      "        1.1001476 ]], dtype=float32)], [array([[-0.01301642,  0.02176397, -0.01237056, ..., -0.00486487,\n",
      "        -0.01185492,  0.9618912 ],\n",
      "       [ 1.0174478 ,  1.0366406 ,  0.91871405, ...,  0.97165287,\n",
      "         0.95066214,  0.984709  ],\n",
      "       [ 0.3364    ,  0.02618098,  0.00900476, ...,  0.17587498,\n",
      "         0.4502696 ,  0.7505151 ],\n",
      "       ...,\n",
      "       [ 1.0139707 ,  1.3948851 ,  0.49985772, ...,  0.47529683,\n",
      "         0.93646574,  0.5854732 ],\n",
      "       [ 0.15183885,  0.05571621, -0.00849169, ...,  0.25179467,\n",
      "         0.5397865 ,  0.6441847 ],\n",
      "       [ 0.22806004,  0.04967729,  0.88225925, ...,  0.58402497,\n",
      "         0.62285644,  0.7500511 ]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "inp = model.model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.model.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "# functor = K.function([inp, K.learning_phase()], outputs)   # evaluation function for GPU?\n",
    "\n",
    "# Testing\n",
    "# test = np.random.random((269))[np.newaxis,...]\n",
    "layer_outs = [func([X]) for func in functors]\n",
    "\n",
    "print(layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 269) dtype=float32 (created by layer 'structual_data')>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 269) dtype=float32 (created by layer 'structual_data')>,\n",
       " <KerasTensor: shape=(None, 48) dtype=float32 (created by layer 'dense_14')>,\n",
       " <KerasTensor: shape=(None, 48) dtype=float32 (created by layer 'dense_15')>,\n",
       " <KerasTensor: shape=(None, 30) dtype=float32 (created by layer 'dense_16')>,\n",
       " <KerasTensor: shape=(None, 30) dtype=float32 (created by layer 'dense_17')>,\n",
       " <KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'dense_18')>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.000000000000004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.log(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(30,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}